{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Un-supervised : \n",
    "we have set of features we find underlying structure in data or find clusters and make some prediction, not have class labels\n",
    "or target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Unsupervised Learning :\n",
    "(Market basket Analysis, Semantic clustering, Delivery Store Optimization, Identify accident prone areas)                      \n",
    "which has not labeled data :                                                                                                   \n",
    "\n",
    "1.Clustering  (method to divide into clusters(or groups) the data which are similar b/w them)                          \n",
    "               Ex: customer purchase similar products , telecom customer churn                                        \n",
    "\n",
    "2.Association (discover relation b/w the var.)                                                                         \n",
    "               Ex : which products purchased together, like: toothpaste with brush etc. , bread + milk                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Types :                                                                                                                        \n",
    "1.K-Means clustering (Exclusive clustering : in which data points are separated),                                             \n",
    "2.C-Means clustering (Overlapping clustering : in which data points are overlapped or item belong to multiple clusters),      \n",
    "3.Hierarchial clustering (when 2 clusters have parent-child relationship or a tree like structure),                           \n",
    "4.Expectation Maximization(EM) clustering : (uses Gaussian Mixture Models (GMM)).                                               \n",
    "5.DBSCAN clustering.                                                                                                         \n",
    "            \n",
    "Association Rule Mining :                                                                                                       \n",
    "    -Market Basket Analysis  ( Apriori algorithm )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Clustering analysis is the task of grouping a set of objects (or data points) in such a way that data points in the same group\n",
    "(called a cluster) are more similar to each other than to those in other groups (clusters). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='clustering1.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Types :                                                                                                  \n",
    "\n",
    "1.Hard Clustering : \n",
    "In hard clustering, each data point either belongs to a cluster completely or not.\n",
    "\n",
    "2.Soft Clustering :\n",
    "In soft clustering, instead of putting each data point into a separate cluster, a probability or likelihood of that data point\n",
    "to be in those clusters is assigned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applications of Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Clustering has a large no. of applications spread across various domains. Some of the most popular applications of \n",
    "clustering are:\n",
    "\n",
    "-Recommendation engines                                                                                       \n",
    "-Market segmentation                                                                                            \n",
    "-Social network analysis                                                                                              \n",
    "-Search result grouping                                                                                                  \n",
    "-Medical imaging                                                                                                       \n",
    "-Image segmentation                                                                                                         \n",
    "-Anomaly detection                                                                                                          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K means clustering is an unsupervised machine learning algorithm. An unsupervised learning algorithm is applied on \n",
    "unlabeled data(data without defined categories or groups). The purpose of this algorithm is to find clusters(groups) in the\n",
    "data with the number of clusters being equal to K.\n",
    "The K means clustering works by randomly initializing ‘k’ cluster centers from all the data points.\n",
    "\n",
    "Using Elbow technique : we can find no. of cluster (K) value also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "In KMeans : we have SSE(Sum of squared Error)  and Elbow technique (by which we find K value of clusters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pros :                                                                                                        \n",
    "    K-means is a fast method because it does not have many computations.                                                    \n",
    "Cons :                                                                                                                \n",
    "    Identifying and classifying the groups can be a challenging aspect.                                                \n",
    "    As it starts with a random choice of cluster centres, the results can lack consistency.                                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DBSCAN is a clustering method that is used to separate clusters of high density from clusters of low density. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Based on a set of points (let’s think in a bidimensional space as exemplified in the figure),\n",
    "DBSCAN groups together points that are close to each other based on a distance measurement (usually Euclidean distance) and \n",
    "a minimum number of points. It also marks as outliers the points that are in low-density regions.\n",
    "\n",
    "The DBSCAN algorithm basically requires 2 parameters:\n",
    "1.eps :\n",
    "    specifies how close points should be to each other to be considered a part of a cluster. It means that if the distance \n",
    "    between two points is lower or equal to this value (eps), these points are considered neighbors.\n",
    "2.minPoints :\n",
    "    the minimum number of points to form a dense region. For example, if we set the minPoints parameter as 5,\n",
    "    then we need at least 5 points to form a dense region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The DBSCAN algorithm should be used to find associations and structures in data that are hard to find manually but that can be\n",
    "relevant and useful to find patterns and predict trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Advantages of DBSCAN:\n",
    "-Is great at separating clusters of high density versus clusters of low density within a given dataset.\n",
    "-Is great with handling outliers within the dataset.\n",
    "\n",
    "Disadvantages of DBSCAN:\n",
    "-Does not work well when dealing with clusters of varying densities. While DBSCAN is great at separating high density clusters\n",
    " from low density clusters, DBSCAN struggles with clusters of similar density.\n",
    "\n",
    "-Struggles with high dimensionality data. DBSCAN is great at contorting the data into different dimensions and shapes. However,\n",
    " DBSCAN can only go so far, if given data with too many dimensions, DBSCAN suffers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Metrics for Measuring DBSCAN’s Performance:\n",
    "Silhouette Score: \n",
    "    The silhouette score is calculated utilizing the mean intra-cluster distance between points, AND the mean \n",
    "    nearest-cluster distance. For instance, a cluster with a lot of data points very close to each other (high density)\n",
    "    AND is far away from the next nearest cluster (suggesting the cluster is very unique in comparison to the next closest), \n",
    "    will have a strong silhouette score. A silhouette score ranges from -1 to 1, with -1 being the worst score possible and \n",
    "    1 being the best score. Silhouette scores of 0 suggest overlapping clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Association Rule Mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Association Rule Mining : is a technique that shows how items are associated to each other\n",
    "                          (like : Bread + butter or eggs or jam , laptop + bag)                \n",
    "             \n",
    "                          support , confidence , lift are three terms used.    ( see : association.png )   \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"association.PNG\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Association rule Mining works on :   relationship  If / Then\n",
    "    EX : If you buy product 'A' Then you may buy product 'B'. like If 'Bread' + Then 'Butter'  and so many eg.\n",
    "        IF 'A' + Then 'B' + 'C' also or 'D' depend on products.\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Apriori Algorithm : \n",
    "    Apriori algorithm finds the most frequent itemsets or elements in a transaction database and identifies association rules\n",
    "    between the items\n",
    "\n",
    "    Works on Measure Association : 1.Support 2.Confidence 3.Lift     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"apriori example.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"support1.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Support (Chocolate) = (4/10)*100 = 40%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"confidence1.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Confidence(Soap -> Perfume) = Support (Soap, Perfume)/Support (Soap)\n",
    "\n",
    "= (30/40) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"lift.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Support(I2) in Lift : occurrence of item Y in transactions, independent of association with item X.\n",
    "    \n",
    "Lift = 1, means the sale of items in association rule are independent of each other,\n",
    "            So we should not find any association between these items.\n",
    "\n",
    "Lift > 1, means the sale of items in association rule has a strong positive relationship.\n",
    "\n",
    "Lift < 1, means the sale of items in association rule has negative/inverse relationship i.e.\n",
    "            they are substitutes of each other and the presence of one can bring down the sale of other or vice versa.\n",
    "    \n",
    "\n",
    "Lift (Soap -> Perfume) = Confidence (Soap, Perfume)/Support (Perfume)\n",
    "\n",
    "                       = 75/40  = 1.87"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
